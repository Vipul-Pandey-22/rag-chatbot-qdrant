# RAG Chatbot with Qdrant

A production-ready Retrieval-Augmented Generation (RAG) chatbot built with FastAPI, React, and Qdrant vector database. Features conversational memory, namespace-based document organization, and HyDE (Hypothetical Document Embeddings) retrieval.

## ğŸš€ Features

- **RAG Pipeline**: Semantic search over your documents using vector embeddings
- **HyDE Retrieval**: Enhanced retrieval using hypothetical document embeddings
- **Conversational Memory**: Maintains context across chat turns using Qdrant
- **Namespace Support**: Organize documents by namespace/project
- **Metadata Search**: Filter documents using custom metadata
- **Modern UI**: React-based chat interface with glassmorphism design
- **Dockerized**: Complete containerization for easy deployment

## ğŸ› ï¸ Tech Stack

### Backend

- **FastAPI**: Modern Python web framework for the API
- **Qdrant**: Vector database for embeddings and conversation history
- **LangChain**: RAG orchestration and prompt management
- **Groq**: LLM provider (llama-3.3-70b-versatile model)
- **Sentence Transformers**: Text embedding model (all-MiniLM-L6-v2)
- **UV**: Python dependency management

### Frontend

- **React**: UI framework
- **Vite**: Build tool
- **Framer Motion**: Animations
- **React Dropzone**: File upload handling

### Infrastructure

- **Docker & Docker Compose**: Containerization
- **Nginx**: Frontend web server

## ğŸ“‹ Prerequisites

- **Docker** and **Docker Compose** installed
- **Groq API Key** (get yours at https://console.groq.com/)
- At least **8GB RAM** (for embedding models)
- **Windows/Linux/macOS** with Docker support

## ğŸ”§ Installation & Setup

### 1. Clone the Repository

```bash
cd "c:\Users\vip\Desktop\Personal Repo\Hackthon"
```

### 2. Configure Environment Variables

Create/edit the `.env` file in the project root:

```bash
GROQ_API_KEY=your_groq_api_key_here
QDRANT_URL=http://qdrant:6333
```

**Important**: Replace `your_groq_api_key_here` with your actual Groq API key.

### 3. Build and Start Services

```bash
docker-compose up -d --build
```

This will start three services:

- **Qdrant** (port 6333): Vector database
- **Backend** (port 8000): FastAPI server
- **Frontend** (port 5173): React UI

### 4. Verify Services

Check all containers are running:

```bash
docker ps
```

You should see:

- `hackthon-qdrant-1`
- `hackthon-backend-1`
- `hackthon-frontend-1`

Test the backend health:

```bash
curl http://localhost:8000/health
```

Expected response: `{"status":"ok"}`

## ğŸ¯ Usage

### Access the Chat UI

Open your browser and navigate to:

```
http://localhost:5173
```

### Upload Documents

1. Click the **"Upload Docs"** tab
2. Either:
   - **Paste text** directly into the text area
   - **Drag and drop** files (`.txt`, `.md`, `.json`, `.csv`)
3. (Optional) Add metadata as JSON
4. (Optional) Set a custom namespace
5. Click **"Upload Document"**

### Chat with Your Documents

1. Switch to the **"Chat"** tab
2. Type your question in the input field
3. Press **Send** or hit **Enter**
4. The bot will:
   - Search your uploaded documents using HyDE
   - Retrieve conversation history
   - Generate a contextual answer
   - Show source documents used

### Namespace Management

- Click the **settings icon (âš™ï¸)** in the top-right
- Change the namespace to organize/isolate document sets
- Default namespace is `"default"`

## ğŸ” How It Works

### Document Ingestion Flow

```
Text Input â†’ Embedding Model â†’ Vector Storage (Qdrant)
                â†“
         [metadata + namespace]
```

### Chat/Query Flow

```
1. User Query
   â†“
2. HyDE: Generate hypothetical answer â†’ Embed
   â†“
3. Search Qdrant (filter by namespace)
   â†“
4. Retrieve conversation history
   â†“
5. Build prompt (context + history)
   â†“
6. Call Groq LLM
   â†“
7. Store turn in conversation history
   â†“
8. Return answer + sources
```

## ğŸ“ Project Structure

```
Hackthon/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ main.py          # FastAPI application
â”‚   â”‚   â”œâ”€â”€ rag.py           # RAG pipeline logic
â”‚   â”‚   â”œâ”€â”€ models.py        # Pydantic models
â”‚   â”‚   â””â”€â”€ settings.py      # Configuration
â”‚   â”œâ”€â”€ Dockerfile           # Backend container
â”‚   â”œâ”€â”€ pyproject.toml       # Python dependencies
â”‚   â””â”€â”€ uv.lock             # Locked dependencies
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ ChatWindow.jsx
â”‚   â”‚   â”‚   â””â”€â”€ UploadDocs.jsx
â”‚   â”‚   â”œâ”€â”€ App.jsx
â”‚   â”‚   â””â”€â”€ index.css
â”‚   â”œâ”€â”€ Dockerfile          # Frontend container
â”‚   â””â”€â”€ package.json
â”œâ”€â”€ docker-compose.yml      # Service orchestration
â”œâ”€â”€ .env                    # Environment variables
â””â”€â”€ README.md              # This file
```

## ğŸ› Troubleshooting

### Backend not starting

**Check logs:**

```bash
docker logs hackthon-backend-1
```

**Common issues:**

- Missing `GROQ_API_KEY` in `.env`
- Qdrant not ready (wait 10s and restart)
- Port 8000 already in use

### HTTP 413 "Request Too Large"

This is fixed in the current version by:

- Limiting retrieved documents to 3
- Truncating each document to 500 chars
- Limiting conversation history to 4 messages

If you still see this, your documents are extremely large. Consider chunking them before upload.

### "unexpected '{' in field name"

This is fixed by escaping curly braces in document text. If you see this:

1. Rebuild the backend: `docker-compose up -d --build backend`
2. Restart: `docker-compose restart backend`

### Frontend not accessible

```bash
# Check if container is running
docker ps | grep frontend

# If not running, start it
docker-compose up -d frontend
```

### Qdrant data not persisting

Data is stored in a Docker volume `qdrant_data`. To check:

```bash
docker volume ls
docker exec hackthon-backend-1 python -c "from qdrant_client import QdrantClient; client = QdrantClient(url='http://qdrant:6333'); print('Documents:', client.get_collection('documents').points_count)"
```

## ğŸ”„ Updating the Application

After making code changes:

```bash
# Rebuild and restart
docker-compose up -d --build

# Or rebuild specific service
docker-compose up -d --build backend
```

## ğŸ›‘ Stopping the Application

```bash
# Stop all services
docker-compose down

# Stop and remove volumes (WARNING: deletes all data)
docker-compose down -v
```

## ğŸ“Š Monitoring

### View Logs

```bash
# All services
docker-compose logs -f

# Specific service
docker logs -f hackthon-backend-1
docker logs -f hackthon-frontend-1
docker logs -f hackthon-qdrant-1
```

### Check Qdrant Collections

```bash
docker exec hackthon-backend-1 python -c "
from qdrant_client import QdrantClient
client = QdrantClient(url='http://qdrant:6333')
print('Documents:', client.get_collection('documents').points_count if client.collection_exists('documents') else 0)
print('Conversations:', client.get_collection('conversations').points_count if client.collection_exists('conversations') else 0)
"
```

## ğŸš€ Production Deployment

For production use:

1. **Set secure environment variables** (don't commit `.env`)
2. **Use HTTPS** with proper SSL certificates
3. **Add authentication** to the FastAPI endpoints
4. **Configure CORS** properly in `backend/app/main.py`
5. **Use managed Qdrant** (Qdrant Cloud) instead of local Docker
6. **Set up monitoring** (e.g., Prometheus + Grafana)
7. **Implement rate limiting** on the API

## ğŸ“ API Documentation

Once running, visit:

```
http://localhost:8000/docs
```

For interactive Swagger API documentation.

## ğŸ¤ Contributing

Feel free to submit issues and enhancement requests!

## ğŸ“„ License

This project is open source and available under the MIT License.

## ğŸ™ Acknowledgments

- **Qdrant** for the excellent vector database
- **Groq** for fast LLM inference
- **LangChain** for RAG orchestration
- **Sentence Transformers** for embeddings
